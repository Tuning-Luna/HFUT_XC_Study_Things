# 课设作业（20 分）

实验任务

## • 1、完成本地化大模型部署

搭建大模型运行环境（包括 GPU / Python / 推理框架等环境配置）
从模型仓库拉取开源大语言模型（如 Qwen、Llama 等）
完成本地推理服务部署，并验证推理能力是否正常

## • 2、调用 API 实现问答功能

调用已部署的大模型 API 完成基础问答功能
支持对话模式并观察模型响应质量

## • 3、增强检索式问答（RAG）功能实现（以下任选其一完成）

选项 A：基于阿里云百炼或者 dify 实现 RAG
创建向量检索服务，导入自定义的本地文档（非公开数据集）
使用向量检索能力，结合大模型构建增强问答流程
实现对私有知识内容的准确问答，并评估检索+生成效果
选项 B：基于 LangChain 实现 RAG
构建文本向量化与知识库（如使用 FAISS / Milvus 等）
通过 LangChain 集成本地模型与向量检索模块
使用非公开数据集验证增强检索问答效果，优化提示词与召回策略

## 成果（提交清单）

报告，建议 5–10 页
