{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e957294",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T13:12:30.32421Z",
     "start_time": "2025-05-02T13:15:26.12130Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义图像转换操作：转换为 Tensor，并进行标准化\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # 转换为 [0,1] 的张量\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))  # 标准化为 [-1,1]\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 获取训练集中第一个批次\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# 输出第一个图像张量的尺寸\n",
    "print(images[0].shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c0ca7de5a7c95",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aab6838e60b52b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T13:17:12.297458Z",
     "start_time": "2025-05-02T13:18:58.323549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "周期: 1/5 - 损失: 0.48\n",
      "周期: 2/5 - 损失: 0.39\n",
      "周期: 3/5 - 损失: 0.37\n",
      "周期: 4/5 - 损失: 0.35\n",
      "周期: 5/5 - 损失: 0.34\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设备设置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义残差块（Residual Block）\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dropout_prob=0.4):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(input_features, output_features)\n",
    "        self.batch_norm = nn.BatchNorm1d(output_features)\n",
    "        self.relu_activation = nn.ReLU()\n",
    "        self.dropout_layer = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # 快捷连接（shortcut）\n",
    "        self.shortcut = nn.Identity()\n",
    "        if input_features != output_features:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(input_features, output_features),\n",
    "                nn.BatchNorm1d(output_features)\n",
    "            )\n",
    "\n",
    "        self._initialize_weights(self.linear_layer)\n",
    "        if isinstance(self.shortcut, nn.Sequential):\n",
    "            self._initialize_weights(self.shortcut[0])\n",
    "\n",
    "    def _initialize_weights(self, layer):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        output = self.linear_layer(x)\n",
    "        output = self.batch_norm(output)\n",
    "        output = self.relu_activation(output)\n",
    "        output = self.dropout_layer(output)\n",
    "        return output + residual\n",
    "\n",
    "# 定义模型结构\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    ResidualBlock(28*28, 256),\n",
    "    ResidualBlock(256, 128, dropout_prob=0.2),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "# 超参数设置\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "l2_regularization_coeff = 1e-4  # L2 正则化系数\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_regularization_coeff)  \n",
    "# L2 正则化由 weight_decay 控制\n",
    "\n",
    "training_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = loss_function(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    training_losses.append(epoch_loss)\n",
    "    print(f\"周期: {epoch+1}/{epochs} - 损失: {epoch_loss:.2f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202beaccdd86e61",
   "metadata": {},
   "source": [
    "## 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9cade52754d5f0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T13:15:57.235666Z",
     "start_time": "2025-05-02T13:15:59.498308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.8572\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1000\n",
      "           1       0.94      0.98      0.96      1000\n",
      "           2       0.68      0.85      0.76      1000\n",
      "           3       0.92      0.81      0.86      1000\n",
      "           4       0.82      0.66      0.73      1000\n",
      "           5       0.94      0.96      0.95      1000\n",
      "           6       0.68      0.66      0.67      1000\n",
      "           7       0.93      0.92      0.93      1000\n",
      "           8       0.95      0.97      0.96      1000\n",
      "           9       0.95      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "AUC (macro-ovr): 0.9886\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "model.eval()  # 设置为评估模式\n",
    "pred_list = []\n",
    "label_list = []\n",
    "prob_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)       # 概率分布\n",
    "        preds = torch.argmax(logits, dim=1)        # 分类结果\n",
    "\n",
    "        prob_list.append(probs.cpu().numpy())      # 概率用于 AUC\n",
    "        pred_list.append(preds.cpu().numpy())      # 预测类别\n",
    "        label_list.append(y_batch.cpu().numpy())   # 实际标签\n",
    "\n",
    "# 合并所有批次结果\n",
    "prob_list = np.concatenate(prob_list)\n",
    "pred_list = np.concatenate(pred_list)\n",
    "label_list = np.concatenate(label_list)\n",
    "\n",
    "accuracy = (pred_list == label_list).mean()\n",
    "print(f\"准确率: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(label_list, pred_list))\n",
    "\n",
    "# 多分类 AUC 计算（macro-ovr 策略）\n",
    "try:\n",
    "    auc_score = roc_auc_score(label_list, prob_list, multi_class='ovr', average='macro')\n",
    "    print(f\"AUC (macro-ovr): {auc_score:.4f}\")\n",
    "except Exception as err:\n",
    "    print(f\"Error Message : {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fb02b253b4e4a",
   "metadata": {},
   "source": [
    "## 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f35afee23e9d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:25:57.276129Z",
     "start_time": "2025-05-02T16:28:57.212154Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# 自定义卷积神经网络（CNN）\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        # 第一层卷积：输入1通道，输出32通道，kernel=3, stride=1, padding=1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 输出尺寸减半\n",
    "\n",
    "        # 第二层卷积：32 -> 64通道\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 展平\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 全连接层，输入是池化后的展平尺寸：64通道 x 7 x 7 = 3136\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # 输出层：10类，使用 Softmax\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)  # dim=1 表示按行进行 softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# L2 正则化函数\n",
    "def l2_regularization(model, lambda_):\n",
    "    l2_norm = sum(torch.sum(param ** 2) for param in model.parameters() if param.requires_grad)\n",
    "    return lambda_ * l2_norm\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=5,\n",
    "    lr=0.01,\n",
    "    lambda_l2=0.001,\n",
    "    device='cpu'\n",
    "):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    training_losses, test_accuracies = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += l2_regularization(model, lambda_l2)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # 手动SGD更新\n",
    "            with torch.no_grad():\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        param -= lr * param.grad\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        training_losses.append(total_loss / len(train_loader))\n",
    "        accuracy = evaluate_accuracy(model, test_loader, device)\n",
    "        test_accuracies.append(accuracy)\n",
    "        print(f\"Epoch {epoch+1}: Loss={training_losses[-1]:.4f}, Accuracy={accuracy:.2f}%\")\n",
    "\n",
    "    return training_losses, test_accuracies\n",
    "\n",
    "\n",
    "# 评估准确率\n",
    "def evaluate_accuracy(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "# 绘制训练过程的损失和准确率\n",
    "def plot_training_progress(losses, accuracies):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(losses, label=\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(accuracies, label=\"Accuracy\", color=\"orange\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 详细模型评估：分类报告、AUC等\n",
    "def evaluate_detailed_model(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X = X.to(device)\n",
    "            logits = model(X)\n",
    "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "            all_preds.extend(preds)\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(y.numpy())\n",
    "\n",
    "    print(\"分类报告:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "        print(f\"AUC Score (OvR): {auc:.4f}\")\n",
    "    except ValueError:\n",
    "        print(\"AUC未计算，可能是类不平衡或其他问题。\")\n",
    "\n",
    "\n",
    "# 训练 CNN 模型\n",
    "cnn_model = CustomCNN()\n",
    "training_losses, test_accuracies = train_model(cnn_model, train_loader, test_loader, epochs=5, lr=0.01, lambda_l2=0.001, device=device)\n",
    "plot_training_progress(training_losses, test_accuracies)\n",
    "evaluate_detailed_model(cnn_model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
